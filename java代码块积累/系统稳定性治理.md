系统稳定性问题处理/ 系统稳定性治理。


|系统异常类型|系统异常描述 （Description）|系统异常表现 （Representation）|系统异常影响 （Effect）|监控指标 （Monitoring）|告警规则 （Warning）|常见问题原因 （Reason）|排查诊断步骤 （Troubleshooting）|应对解决方案 （Action）|
|--|--|--|--|--|--|--|--|--|
|微服务内部异常|微服务Pod自动重启|1.服务波动 服务请求响应时间明显增加或变得不可预测，有时响应正常，有时无响应或响应超时。 2.监控指标异常 可以观察到Pod的重启次数（restart count）持续增加；CPU使用率、内存使用量、磁盘空间等资源指标异常，特别是在重启前后有显著波动 3.Kubernetes事件（Events） 容器重启事件及其原因|1.服务可用性降低 Pod重启过程中会导致服务中断 2.性能波动 自动重启期间，服务可能无法处理新的请求，导致请求积压、延迟增高 3.资源消耗 Pod重启过程中会产生额外的CPU和内存开销，而且短时间内频繁重启可能导致资源使用率升高 4.链路雪崩 触发下游服务的连锁反应，导致整个系统的链路受到影响|Pod 自动重启|1分钟内Pod重启次数>0|1.健康检查失败 Liveness Probe（存活探针）或Readiness Probe（就绪探针）连续失败，Kubernetes会认为容器不健康，进而重启容器 2.容器异常退出 内存溢出（OOM Killed），即容器使用的内存超过了为其分配的最大内存限制，kubelet会自动杀掉容器 3.配置变更 更新了Pod的配置，如容器镜像、环境变量等，Kubernetes会自动重启Pod以应用新的配置|可以参考以下步骤 1.查看Pod状态和事件 登录云平台查看Pod最近发生的事件 2.查看Pod日志 从中找寻是否有程序异常、资源耗尽、配置错误等导致Pod退出 3.检查健康检查探针 确认Liveness Probe和Readiness Probe是否配置合理，探针检查的端点、超时时间、失败阈值等是否可能导致Pod被误判为不健康并重启 4.检查资源限制 检查Pod的资源请求（requests）和限制（limits）是否设置得当,查看容器资源限制，确保没有因资源耗尽（如内存溢出OOMKill）导致Pod被重启 5.监控指标分析 查看Pod的CPU、内存、磁盘、网络等资源使用情况，以及重启次数等相关指标，判断是否有资源异常导致重启 6.排查配置变更 Pod重启前是否进行了配置变更 7.检查网络和存储 检查Pod的网络配置和依赖的持久化存储，看是否存在网络不通、存储访问异常等情况|重启是系统自愈的过程，需要从根本上找到原因 例如： 健康检查失败 1.如果系统出现突发流量，导致请求堆积，  进行pod扩容，并分析流量来源是否合规 2.如果过于严格的健康检查导致Pod频繁重启，可以适当降低要求 3.中间件或网络异常导致健康检查失败，需进行问题修复  容器异常退出 1.应用本身出现oom现象，需要查看监控，针对该pod做监控，方便下次保留现场，分析dump文件|
|微服务接口响应失败率高|1.接口访问失败率高 接口请求失败率高，但是仍然有接口请求成功 2.接口频繁告警，但测试访问时业务仍然能够运行|1.业务异常 影响业务使用 2.系统稳定性 影响系统稳定性|接口失败率|xx时间内接口失败率> x%  xx时间接口失败次数 > x|1.依赖服务部分服务节点宕机 2.带宽占用高 3.部分服务所在宿主机未开白或者网络策略调整 4.依赖服务GC异常|1.分析日志 2.检查依赖服务运行状态 检查各个节点运行状态，CPU占比 3.检查网络 检查网络带宽情况，检查网络连通性 4.查看jvm信息 检查线程池空闲情况，检查gc停顿时间|1.完善监控机制 支持监控cpu、jvm、带宽、网络、服务节点状态 2.服务宕机告警 3.完善沟通同步机制 依赖方业务出问题，需及时同步调用方研发||
|微服务接口响应耗时很长|1.系统卡顿 用户在使用系统时，感受到明显的延迟，导致操作不流畅。 2.业务数据单边 业务数据在不同系统间不一致 3.监控指标异常 服务器或中间件的CPU、内存、磁盘IO等明显升高。 4.服务QPS降低 服务QPS明显降低或者低于同时段平均水平|1.业务超时失败 响应时间超过调用方设置的超时时间导致业务出现超时异常 2.业务效率降低 业务处理速度变慢，整体业务效率降低。 3.系统资源消耗增加 长时间的接口调用导致占用更多的系统资源，如CPU、内存等。 4. 数据一致性问题 在分布式事务中，某个服务的响应延迟可能导致事务状态不一致，从而引发数据错误。 5.服务并发处理能力受限 服务出现瓶颈，无法及时处理的请求出现报错或降级|服务P99|P99>x秒(具体时长根据业务实际情况而定)|1. 网络问题 网络传输协议的效率、带宽限制以及网络拥堵都可能导致接口响应耗时增加 2. 访问量过大 大量并发请求时导致服务过载，接口响应耗时增长 3. 调用链路过长 接口涉及的调用链路过长，部分节点耗时增加就会导致接口整体耗时明显变长 4. 单业务体积过大 单次请求处理大量数据或涉及复杂计算流程，导致处理时间过长 5. 数据库慢查询 接口查询SQL优化不合理，导致慢查询 6. 硬件问题 服务器或存储设备的故障|1. 查看服务监控确定问题的范围，检查CPU、内存、磁盘I/O、网络等是否正常。 2. 检查网络状况，检查是否有相关告警。使用ping、traceroute或telnet等工具来检查网络连通性和延迟，确认是否存在网络瓶颈或故障。 3. 检查应用和服务的日志，看是否有异常或错误信息。 4. 检查数据库是否存在慢查询。同时，检查数据库的负载和资源使用情况，以判断是否是数据库性能问题导致的接口响应慢。 5. 如果系统使用了缓存，检查缓存的命中率 6. 检查应用线程使用情况，是否并发处理能力不足或线程使用不当 7. 如果接口调用了外部服务，检查外部服务的响应时间是否正常 8. 检查代码和算法，查看代码中是否有逻辑不合理的地方|1.优化业务逻辑和代码 简化业务逻辑，减少不必要的调用和计算。优化代码结构和算法，避免重复计算和不必要的循环。使用高效的数据结构和算法来加速数据处理。 2.数据库优化 对接口SQL进行优化，使用索引、分区等技术提高查询效率。数据库分库分表，减轻单个数据库的压力。 3.网络优化 增加带宽，提升网络传输速度。考虑使用专线或优化网络拓扑结构，减少网络延迟。 4.使用缓存和消息队列 将常用数据放到缓存中，减少对数据库的访问。使用消息队列进行异步处理，将耗时操作放入队列中，避免阻塞主线程。 5.接口粒度拆分和并行调用 根据实际业务需求，将接口粒度进行细化，拆分成多个小接口，提高系统的并发处理能力。并行调用没有依赖关系的服务，减少整体响应时间。 6.压力测试和性能评估 进行压力测试，模拟大量并发请求场景，评估系统性能瓶颈。根据测试结果进行性能调优，优化瓶颈环节。||
|数据库连接池获取超时|1. 服务超时 服务接口出现大面积超时 2. 服务监控异常 P99、接口错误率、线程数超高 3. 数据库负载高 数据库CPU、内存、磁盘IO等明显升高。|1.系统性能下降 获取数据库连接超时导致请求处理速度变慢，从而影响整个系统的性能。用户可能会感受到页面加载缓慢、操作响应迟钝等问题。 2.服务调用失败 如果系统依赖于数据库连接来执行某些操作，那么这些操作可能会失败从而导致业务流程中断。 3.资源耗尽： 过多的线程或进程可能会因为等待连接而被阻塞，从而消耗大量的系统资源。 4.事务失败 连接池获取超时导致事务无法及时完成，事务可能会失败。|获取数据库连接池超时|获取数据库连接池超时数量>1|1.连接池配置不当 连接池的最大连接数设置过小，或者连接超时时间设置过短。 2.数据库性能瓶颈 硬件资源不足 3.网络问题 应用与数据库服务器之间的网络延迟或不稳定。 4.代码问题 查询SQL优化不足，索引缺失;代码中可能存在连接泄露，即没有正确关闭数据库连接，导致连接池中的连接无法被复用，最终耗尽。|1. 分析日志，查看应用程序和数据库连接池的日志，寻找与连接池相关的错误信息或警告。 2. 检查数据库的性能监控指标，包括CPU使用率、内存使用率、磁盘I/O、网络I/O等。 3. 检查数据库连接池配置，确认最大连接数、最小连接数、超时时间等参数设置是否合理。 4. 检查网络连接状况，使用ping、traceroute等工具测试应用服务器与数据库服务器之间的网络连接，检查是否有丢包、延迟等问题。 5. 检查应用程序中与数据库连接相关的代码，确保每次使用完数据库连接后都正确关闭。|1.优化连接池配置 根据系统的并发量和业务需求，合理设置连接池的最大连接数、最小连接数以及连接超时时间。 2.提升数据库性能 优化SQL查询、添加必要的索引、定期归档；考虑分库分表、读写分离；根据数据库的负载情况扩展硬件资源。 3.改善网络状况 检查应用服务器与数据库服务器之间的网络连接，确保网络稳定且延迟低。考虑将应用服务器与数据库服务器部署在同一网络区域，以减少网络传输的开销。 4.修复代码中的连接泄露 对代码进行审查，确保在每次使用完数据库连接后都正确关闭连接。 5.引入连接池监控 引入连接池监控工具，实时监控连接池的使用情况，包括连接数、空闲连接数、等待连接数等指标。根据监控数据调整连接池的配置参数，确保连接池能够满足系统的需求。||
|JVM内存OOM|1.服务无法启动 程序启动时报错，无法启动 2.服务Pod不定期重启 Pod跑了一段时候后，服务挂了，导致异常重启 3.监控指标异常 服务器或中间件的CPU、内存、网络连接数等明显升高。|1.系统性能下降 垃圾回收处理不过来导致请求处理速度变慢，从而影响整个系统的性能。用户可能会感受到页面加载缓慢、操作响应迟钝等问题。 2.服务调用失败 服务在请求繁忙时突然重启，那么请求操作可能会失败从而导致业务流程中断。 3.资源耗尽： 过多的线程或进程可能会因为未释放，从而消耗大量的系统资源。|IO监控 线程数监控 文件句柄数监控 内存监控|IO监控>x 线程数监控>x 文件句柄数监控>x 内存监控>x|1.堆内存溢出（Heap OOM） 创建的对象过多，并且对象长时间存活，打开太多文件、线程数过多等。 应用程序中存在内存泄漏，长时间无法释放不再使用的对象。 2.方法区内存溢出（Metaspace OOM） 类加载过多，应用程序加载了大量的类，并且这些类的云数据占用了过多的方法区内存。 类加载器泄漏，自定义的类加载器未正确实现或第三方库导致的类加载器泄漏，无法释放已加载的类。 3.栈内存溢出（Stack OOM） 递归调用过深，递归算法实现不当，导致递归深度过大，超出了线程栈的大小限制。 线程创建过多，应用程序创建了大量的线程，并且每个线程的栈内存分配过多，导致系统资源耗尽。|1.查找关键报错信息 如java.lang.OutOfMemoryError: Java heap space 2. top命令 ps命令 对当前服务内存服务有大致了解 3.利用jstat查看JVM GC情况 看full gc是否明显大于young gc，且非常频繁，如果是 说明程序有大内存对象得不到释放。 4.使用内存分析工具 生产dump文件，对dump出来的堆储存快照进行分析，分析清楚是内存泄漏还是内存溢出。|1.优化代码和数据结构/算法 减少不必要的对象创建，使用合适的数据结构来存储数据，避免过大的集合和数组。使用合适的递归算法，减少递归深度。 2.内存泄漏检测和监控 利用内存分析/监控工具进行堆内存分析/监控，找到内存泄漏的根源，并及时修复。 3.调整JVM参数 根据服务器的物理内存大小，适当调整JVM的堆内存大小。通过-Xmx和-Xms参数设置堆内存的最大值和初始值，避免频繁的内存扩张和收缩。限制方法区大小，通过-XX:MaxMetaspaceSize参数设置方法区的最大值，避免无限制增长。调整线程栈大小，通过-Xss参数设置线程栈的大小。||
|微服务Pod启动失败|1.服务无法正常启动 程序启动时报错，无法正常启动，启动失败 2.服务启动异常，反复重启 服务启动异常，反复重启 3.服务未被调度，一直处于调度状态 服务pod一直处于调度状态，未被调度|1.业务异常 服务启动不成功，影响业务使用 2.系统稳定性 服务启动不成功，无法提供服务，服务内部整体无法闭环 3.集群异常 集群pod状态显示异常或异常重启飙升|集群pod异常告警|pod重启次数>x 数据库异常告警|1.pod镜像拉取不对    pod镜像不对，导致拉取失败，或者镜像拉取无权限 2.节点cpu或者内存不足    镜像设置的resource，cpu或者内存无法满足当前需求，导致集群无法调度选择对应节点 3.服务本身异常    服务本身启动异常，如数据库无法连接、redis无法连接、应用代码问题【应用无法获取到配置或连接不上配置中心，应用内部循环依赖、应用混淆导致code问题、应用class类找不到】 4. 探活配置异常     服务启动接口和探活接口不一致，导致探活失败一直重启；服务探活配置时长比较短，应用启动时间比较长导致k8s探活机制失败|1.查看集群状态   查看集群的状态是否正常，判断本次部署的事件是否是sche处于调度状态，检查是否是cpu和resour资源问题；查看部署的镜像版本是否拉取正确 2.查看应用日志   查看后端服务应用日志，结合启动的错误日志进行分析，看是否是应用代码问题【应用无法获取到配置或连接不上配置中心，应用内部循环依赖、应用混淆导致code问题、应用class类找不到】之一，查询资料结合业务code定位排查 3.寻求运维同事协助 找韵味协助排查，查看是否是集群调度故障或者是本身服务部署故障问题|1.监控告警 配置集群本身的资源监控告警，当集群资源本身不足时，告警群知会 2.做好代码coding review 应用服务发布过程前，及时做好coding review,保证服务在本地能够正常运行 3.做好基础设施配置 保证服务的探活做成标准话配置，结合不同的业务适当提前预知分享 4.知识培训 定期举行技术分享，对集群知识，应用服务构建最佳实际做好分享||
|内部依赖系统异常|下游接口访问不通|1.接口访问失败 请求下游接口失败，返回常见HTTP错误码 2.接口调用超时 调用下游接口超过等待超时时长 3.无响应 接口调用后没有响应 4.下游服务不可用 调用下游服务返回服务不可用 5.dubbo线程池满 dubbo在并发场景下线程池满会导致请求失败，返回调用者“Thread pool is EXHAUSTED”|1.业务异常 影响业务使用 2.影响用户体验 接口稳定性影响C端用户体验 3.数据同步失败 同步接口访问不通，会造成同步失败 4.线程阻塞 容易引发诸如线程池满、接口无响应、服务宕机。|error日志监控告警|1.对于关键接口，error建议均告警 2.非关键接口可考虑配置接口失败率|1.下游服务异常 下游发版、下游服务宕机等情况导致接口访问失败 2.网关控制 接口未开通白名单、网关策略调整、新接口内网域名或者host文件未配置 3.jvm代理访问限制 pod能访问接口，但是服务无法访问报502,域名需配置忽略走代理 4.vpc带宽占用 vpc带宽被其它业务占用满了，导致接口通过vpc访问失败 5.调用下游或者下游调用依赖方接口超时时间设置太小 对于部分大数据查询接口可能需要设置合理的接口超时时间，避免查询太久主动CANCEL|1.查看接口日志 查看接口日志，看接口访问不通原因，排查状态码、响应信息、报错日志。 2.ping下域名 对于接口不通，可先ping域名，看域名连通性。 3.wget、curl或者postman请求接口 如果ping通了，可对单个接口进行请求，看接口请求情况。如接口pod访问不通可找运维查看网关策略，网络资源情况。如接口pod能访问通，但是服务请求不通，先看下代码路径，协议等是否正确；如代码均无问题可找运维看下诸如内网域名是否配置，是否需要忽略jvm代理。 4..寻求运维同事协助 找运维协助排查。查看ip是否开白、网关策略、jvm代理配置、内网域名/host是否配置|1.监控告警 对下游依赖的接口，异常场景做好日志打印和监控告警配置。同时大数据查询接口可监控接口时长，方便后续优化处理。 2.健康检查 对定时型的业务接口，在空闲时期可对接口进行连通性调用。做好健康检查，提前暴露风险。 3.故障演练 定期做好故障演练。 4.发版信息同步 建立健全所有依赖方发版同步机制，发版前可进行群同步、邮件同步。 5.代码优化 在进行代码开发和CR时需要考虑代码回滚策略，接口重试策略（特殊场景需考虑重试步长），关键业务和产品沟通好降级策略。 6.带宽评估 根据高峰期或者业务预期评估访问量，根据出口和入口报文长度评估接口请求占用带宽资源，合理评估带宽使用情况。同时监控带宽使用。|
|下游接口响应超时|1. 服务调用超时 相关接口出现超时  2. 服务监控异常 P99、接口错误率|1. 服务调用失败 依赖的下有接口响应超时，那么这些操作可能会失败从而导致业务流程中断。|接口错误率、P99|接口错误率 > 0.1|1. 调用方出口 IP 被封禁 误将调用方出口 IP 当成攻击者 IP 进行封禁。 2. 网络问题 调用方与下游的网络不通畅。 3. 下游系统宕机 下游系统宕机，导致无法及时响应请求。 4. 下游系统压力大，响应慢下游系统由于请求量过多，处理速度慢，导致相应速度慢。|1. 分析日志，查看错误错误信息或警告。 2. 检查网络连接状况，使用ping、traceroute等工具测试应用服务器与数据库服务器之间的网络连接，检查是否有丢包、延迟等问题。 3. 与安全团队确认是否对出口 IP 封禁。 4. 与下游团队确认是否系统宕机或系统压力大。|1. 改善网络状况 检查应用服务器与数据库服务器之间的网络连接，确保网络稳定且延迟低。考虑将应用服务器与数据库服务器部署在同一网络区域，以减少网络传输的开销。 2. 将出口 IP 加入安全白名单 与安全团队沟通，将出口 IP 加入白名单，避免误伤。 3. 引入监控工具 引入监控工具，实时监控接口错误率，当达到阈值时及时介入排查。 4. 与下游系统建立排查群 与下游系统建立问题排查群，发生大规模异常时可及时沟通、反馈。||
|下游接口响应HTTP错误|1.接口访问返回4xx错误 请求下游接口返回404、403、401等HTTP错误码  2.接口调用返回5xx错误 请求下游接口返回502、504、503、500等HTTP错误码  3.监控指标异常 下游接口调用监控失败率剧增|1.服务调用失败量很高 部分接口或者整个服务的请求错误率突然很高  2.服务调用耗时很长 部分接口或者整个服务的p99延时突然很高|接口错误率 接口P99延时|1分钟内接口失败率> x% 1分钟内接口p99大于3s> x%|1.下游接口返回404 请求URL不正确，或者下游接口URL有变更  2.下游接口返回403 HTTP 403 Forbidden，可能是请求URL不正确，或者下游接口路由配置禁止访问  3.下游接口返回401 401 Unauthorized，表示下游接口开启了HTTP 认证而调用方未认证通过  4.下游接口返回502 502 Bad Gateway错误表示Nginx从后端服务收到了无效的响应。通常原因可能是后端返回了空响应，或者Nginx与后端服务之间的连接意外中断  5.下游接口返回504 504 Gateway Timeout错误表示Nginx从后端服务接收响应的超时时间已到，但后端服务尚未完成响应。通常原因可能是后端服务处理请求的时间过长，或者网络问题导致Nginx与后端服务之间的通信延迟  6.下游接口返回503 503 Service Unavailable错误表示Nginx无法从后端服务获得响应，通常是由于后端服务暂时不可用。通常原因可能是后端服务正在维护升级，或者后端服务宕机  7.下游接口返回500 500 Internal Server Error错误表示服务器内部错误，通常是微服务框架在处理请求过程中遇到未知的系统错误||||
|外部依赖系统异常|集团接口认证异常|1.登录异常 非逃生登录失败，无法正常登录  2.http接口不能正常路由到应用服务器 部分使用http协议的接口无响应|1.应用服务使用异常 非逃生登录失败，用户无法正常使用应用系统  2.部分业务功能无法正常使用 部分http协议接口无响应，影响部分业务功能|暂无|暂无|1.bam日志级别不合理 apache-bam服务日志设置为3(生产日志应设为1）应用生成大量日志文件，导致节点磁盘空间不足，驱逐容器。  2.bam服务节点数不合理 apache-bam服务是单节点，一个挂了没有兄弟节点顶替  3.bam服务升级到1.1.6，升级后的版本生产环境只支持443端口 升级bam服务到1.1.6版本，http请求会强转为https，http接口请求302重定向，如果应用服务的接口需要走http协议，会影响接口的正常访问|1.查看bam服务pod状态和事件 登录容器监控平台查看bam服务pod节点事件  2.查看bam服务pod日志 从中找寻是否有程序异常、资源耗尽、配置错误等导致pod退出   3.检查pod节点应用服务器磁盘情况 检查pod的节点磁盘容量，是否产生大量日志文件占用磁盘空间，导致容器被驱逐   4.检查http接口是否被重定向 检查应用服务http相关接口，是否被重定向后出现308错误|1.调整bam服务pod节点数   2.调整bam服务配置文件，将日志打印级别调整到合理级别  3.降低bam服务版本|
|阿里云OSS读写异常|||||||||
|云存储异常|||||||||
|数据库异常|MySQL数据库CPU占用率高|1、系统响应慢 CPU占用率高可能导致系统处理请求的速度变慢，用户可能会遇到页面加载缓慢或请求超时的情况。 2、数据库连接问题 高CPU使用率可能导致数据库连接数增加，超出数据库的最大连接限制，从而导致新的连接请求被拒绝。 3、查询性能下降 复杂的查询或不足的索引可能导致查询执行效率低下，进一步增加CPU的负担。|1、性能下降 CPU占用率高意味着数据库在处理查询和操作时遇到了瓶颈，导致响应时间延长，系统吞吐量下降。 2、资源争用 高CPU使用率可能导致其他系统资源（如内存、磁盘I/O）的争用，进一步影响系统的整体性能。 3、错误和异常 由于CPU资源不足，数据库可能无法及时处理请求，导致超时、连接失败等错误和异常增多。 4、稳定性问题 长时间的高CPU使用率可能导致数据库实例崩溃或不稳定，影响业务的连续性和稳定性。|cpu_usage_idle|cpu使用率大于70%|1、查询语句设计不当 复杂的查询语句、未优化的查询语句、缺少合适的索引等都可能导致MySQL的CPU占用过高。 2、数据量过大 当数据库中的数据量过大时，查询和处理数据的时间会变长，从而导致CPU占用过高。 3、硬件配置不足 如果服务器的硬件配置不足以支撑MySQL的运行，比如CPU、内存、磁盘等方面的配置都不足，都可能导致CPU占用过高。 4、业务高并发 业务繁忙或并发窗口可能导致CPU占用过高。 5、数据库对象设计不合理 如表索引设计不合理等，也可能导致CPU占用过高。|1、确认问题 首先确认MySQL数据库的CPU占用率确实过高，可以通过数据库监控面板或MySQL自带的性能监控功能来查看。 2、查看连接情况 使用SHOW FULL PROCESSLIST命令查看数据库的连接情况，确认是否有过多的连接或空闲连接不足。 3、SQL慢查询 通过慢SQL日志查询是否有慢查询，使用EXPLAIN命令检查慢SQL是否有执行效率低的查询语句或缺少索引的情况。 4、查看线程和会话 使用pidstat命令查看高CPU占用率的线程，并通过查询performance_schema.threads表定位到具体的SQL语句或会话ID。 5、优化查询 根据慢查询和定位到的SQL语句，优化查询条件和添加索引，提高查询效率。 6、检查硬件和配置 确认服务器的硬件配置是否足够支撑MySQL的运行，并检查MySQL的配置参数是否合理，如缓冲区大小、连接池大小等。|1、优化查询语句 通过分析和优化查询语句，减少不必要的资源消耗。可以选择适当的索引策略，优化查询性能，减少查询返回结果的数量，避免使用SELECT *等。 2、优化数据库配置 调整MySQL的配置参数，如增加缓冲区大小、调整并发连接数、配置查询缓存等，以提高数据库的性能并降低CPU负载。 3、监控和优化数据库性能 实时监控数据库的性能表现，通过工具如SHOW FULL PROCESSLIST、EXPLAIN等查看数据库的连接情况和慢查询，及时发现和解决问题。 4、升级硬件 如果服务器的硬件配置不足以支撑MySQL的运行，可以考虑升级硬件，如增加CPU、内存等。|
|MySQL数据库连接数过高|1、响应时间延长 用户在进行数据库操作时，可能会遇到响应时间明显延长的情况，因为数据库需要处理大量的连接请求。 2、错误提示 当连接数达到MySQL配置的最大连接数时，新的连接请求可能会被拒绝，并返回“Too many connections”错误。 3、监控告警 前期：出现系统延迟和系统错误告警：P99超时和系统错误、错误率和SLA等告警；出现MySQL连接数过高告警； 中期：叠加出现JVM告警：CPU和负载告警； 后期：出现系统502错误或容器重启等告警；|1、性能下降 由于过多的连接竞争系统资源，可能导致数据库的整体性能下降，查询速度变慢。 2、资源耗尽 过高的连接数可能导致系统资源（如内存、CPU）被耗尽，进一步影响数据库的稳定性和可用性。 3、服务崩溃 如果连接数持续过高，并且没有得到及时的处理，可能会导致服务崩溃，无法正常提供服务。|mysql_global_status_max_used_connections/mysql_global_variables_max_connections  or  mysql_global_status_connection_errors_total|MySQL连接达到最大连接数的80%|1、连接泄露 应用程序在使用完数据库连接后没有正确释放，导致连接数持续增加。 2、连接池设置不合理 连接池的大小设置不合理，可能太小无法满足并发请求，或者太大导致资源浪费。 3、长时间运行的查询 某些查询执行时间过长，占用了连接资源，导致其他请求无法获取连接。 4、系统资源不足 服务器内存、CPU等资源不足，无法处理大量的并发连接请求。 5、没有采用缓存技术 没有使用缓存技术来减少对数据库的直接访问，增加了数据库连接的需求。 6、数据库未经过优化 数据库表设计不合理、索引缺失、查询语句未优化等，都可能导致查询效率低下，连接数增加。|1、查看当前数据库连接数 使用SQL语句 SHOW GLOBAL STATUS LIKE 'Threads_connected'; 查询当前连接数，以确定是否存在连接数过多的问题。 2、检查连接数的配置限制 使用SQL语句 SHOW VARIABLES LIKE 'max_connections'; 查询数据库的最大连接数限制，确认是否配置得过低。 3、分析连接占用情况 a)、使用SQL语句 SHOW PROCESSLIST; 查看当前数据库的活动连接，找出占用连接较多的进程或查询。 b)、分析长时间运行的查询或占用资源的进程，优化这些查询或调整相关配置。 4、检查应用程序 a)、确认应用程序是否正确管理数据库连接，确保在使用完数据库后正确关闭连接。 b)、检查应用程序的并发请求量，如果并发量过大，考虑优化应用程序或增加服务器资源。 5、日志分析 分析MySQL的错误日志和慢查询日志，查找与连接数过高相关的警告或错误信息。|1、调整最大连接数限制 通过修改MySQL的配置文件（通常是my.cnf或my.ini），找到[mysqld]部分，增加或修改max_connections参数的值，以允许更多的并发连接。然后重启MySQL服务使配置生效。 2、优化应用程序 a)、检查应用程序是否正确管理数据库连接，确保每个连接在使用完毕后都被正确关闭和释放。 b)、使用连接池技术来复用数据库连接，减少频繁创建和关闭连接的开销。 3、优化数据库查询 a)、分析执行时间较长的查询，优化这些查询的SQL语句，提高查询效率。 b)、为数据库表添加合适的索引，以提高查询速度。 4、增加系统资源 如果服务器硬件资源不足，考虑升级服务器硬件，如增加内存、提升CPU性能等。 5、使用缓存技术 引入缓存机制，如Redis，减少对数据库的直接访问，降低连接需求。 6、监控告警 增加数据库连接数和相关性能指标监控和告警，提升快速感知能力，做到先于用户发现问题，一旦发现问题之后，可以快速预警、发现、定位和处理问题； 7、调整连接超时时间 通过调整wait_timeout和interactive_timeout参数的值，控制非交互和交互连接的超时时间，确保不活跃的连接能够及时关闭。||
|MySQL数据库锁等待数量很高|1.事务执行受阻 当锁等待数量很高时，意味着许多事务正在等待获取锁资源，这可能导致事务执行受阻，无法按时完成。 2.响应时间延长 由于事务需要等待锁资源，系统的响应时间可能会明显延长，用户可能会感受到操作延迟或超时。 3.吞吐量下降 高锁等待数量可能导致系统吞吐量下降，因为事务在等待锁的过程中无法处理其他请求。|1.锁无法释放 行级锁长时间无法释放，导致其他事务的等待。 2.产生死锁 长事务的锁长时间不能释放，容易与其他事务产生死锁。 3.MySQL崩溃 MDL锁(元数据锁)hold住大量事务，造成MySQL崩溃。|mysql_global_status_locks_waited|锁等待数量和持续时间超过一定國值时|1.执行DML操作没有commit 当执行DML操作没有提交事务时，其他尝试访问相同数据行的事务将被阻塞，从而导致锁等待数量增加。 2.表索引设计不当 不恰当的索引设计可能导致数据库查询效率降低，进而增加锁定的时间。。 3、长事务 长时间运行的事务会持有锁资源更长时间，从而增加其他事务等待锁的时间。|1.查看当前锁等待情况 a)、使用SHOW ENGINE INNODB STATUS;命令查看InnoDB引擎的当前状态，其中包含了锁等待的详细信息。 b)、使用SHOW PROCESSLIST;或SHOW FULL PROCESSLIST;命令查看当前MySQL中正在执行的所有线程，包括它们的状态和等待的锁信息。 2.分析锁等待日志 如果开启了InnoDB的锁等待日志（innodb_print_all_deadlocks设置为ON），则可以在错误日志中查找死锁相关的信息。 分析死锁日志，找出导致死锁的事务和SQL语句，优化这些SQL语句或调整事务逻辑。 3.检查事务和锁持有时间 分析长事务，找出持有锁时间过长的事务。可以使用SHOW ENGINE INNODB STATUS;中的TRANSACTIONS部分来查看当前正在运行的事务。 找出持有锁的事务对应的SQL语句，考虑是否可以优化这些SQL语句以减少锁的持有时间。 4.分析SQL执行计划 使用EXPLAIN命令分析有问题的SQL语句的执行计划，查看是否可以利用索引来提高查询效率，从而减少锁的持有时间和范围。 5.优化表结构和索引 根据SQL执行计划的分析结果，优化表结构和索引设计，减少查询对锁的依赖。|1.优化查询语句 a)确保查询语句尽可能高效，避免使用低效的查询方式。 b)增加索引，以提高查询效率，减少锁等待时间。 2.事务拆分和隔离级别调整 如果某个事务的操作涉及到大量的数据，并且持有锁的时间很长，可以考虑将长事务拆分为多个短事务，减少持有锁的时间。同时，根据具体业务场景，适当降低事务的隔离级别也可以减少锁等待的概率，但需要注意可能引发的脏读、不可重复读等问题。 3.提高硬件配置和优化参数设置 增加服务器的硬件资源，如CPU、内存、硬盘等，可以提高数据库的并发处理能力，减少锁等待的可能性。此外，还可以优化数据库的参数设置，以更好地应对锁等待问题。 4.合理设计数据库表结构和索引 避免使用过多的锁粒度，减少锁冲突的概率。合理选择索引字段，以提高查询效率，减少锁等待时间。 5.使用更高级的锁策略 如果数据库中存在高并发的写操作，可以考虑使用更高级的锁策略，如乐观锁或分布式锁，以更好地管理锁资源。 6.升级MySQL版本 如果使用的是较旧的MySQL版本，考虑升级到最新版本。新版本可能包含性能改进和锁机制的优化。 7.监控锁等待情况 监控锁等待的数量和持续时间，当锁等待数量或持续时间超过阈值时，及时收到报警并进行处理。||
|MySQL数据库大量事务未提交|1.数据库性能下降 系统增删查改数据库相关的操作明显变慢 2.系统 druid 连接池不够用或者耗尽 系统报错 GetConnectionTimeoutException，CannotGetJdbcConnectionException 等 3.系统吞吐量下降 连接池里面的线程在等待事物提交，能用的线程数变少，系统大部分业务请求都在等待线程|1.MySQL操作变慢 跟MySQL相关的操作都会收到影响，耗时变长，一直在等待线程池资源释放 2.系统响应变慢 监控可以看到整个系统请求耗时增加，吞吐量下降|定期查询information_schema.innodb_trx表，这个表包含了当前运行的所有事务信息|检查是否有长时间运行的事务|1. 程序错误 代码中存在逻辑错误，导致事务未能正常提交。 2. 连接丢失 数据库连接意外中断，导致未提交的事务未被执行。 3. 服务器崩溃 MySQL服务器崩溃，导致正在进行的事务未能完成。 4. 长时间运行的事务 大事务运行时间过长，可能在事务执行过程中发生了某些问题导致未提交。 5. 锁等待超时 事务等待获取锁超时，可能部分DML操作未执行。 6. 手动开启的事务 开发者手动开启了事务但未提交或回滚。|1. 查看当前运行的事务 SHOW ENGINE INNODB STATUS; 2. 检查事务是否长时间运行 SELECT * FROM information_schema.innodb_trx WHERE TIME_TO_SEC(TIMEDIFF(NOW(), trx_started)) > 600; 3. 分析慢SQL, 找出执行时间长的SQL语句 事务未提交大部分情况都是由于有慢SQL导致的事务未提交，排查时间时间长的SQL也可以排查部分场景 4. 分析查看系统报错情况，看有没有连接池相关的报错 未提交的事务会占用连接池的线程，导致后面来的请求获取不到线程 5. 如果需要，可以使用KILL命令终止长时间运行的事务 对于时间长的事务可以直接kill或者回滚|1. 检查并提交未完成的事务 使用SHOW ENGINE INNODB STATUS;查看锁等待信息。 使用SHOW PROCESSLIST;查看当前运行的事务和锁定的资源。 如果确定事务可以提交，使用COMMIT语句提交事务。 2. 调整数据库配置 增加innodb_buffer_pool_size的值，以提高缓存效率。 调整innodb_log_file_size和innodb_log_files_in_group，以优化重做日志的大小和数量。 调整innodb_lock_wait_timeout，增加锁等待超时时间。 3. 监控数据库资源使用情况 检查数据库内存，磁盘和其他资源监控，看是否正常。 4. 优化事务处理 减少单个事务的大小和复杂度。 使用批处理执行多个操作，减少单次事务对数据库的影响。||
|MySQL数据库突然连接不上|1. 服务监控异常 服务接口或方法函数异常（链路中存在mysql依赖）、P99、接口错误率 2. 服务超时 服务接口出现大面积超时 3.客户端异常提示 Too many connections，超出mysql最大连接数|所有依赖mysql的服务均出现异常|自定义异常监控指标、接口错误率、P99|自定义异常告警|1、网络连通性问题 - 网络波动、安全组配置 2、mysql账号权限问题 3、数据库服务不可用 4、数据库连接资源不足|1、在出现异常的客户端容器或主机中telnet mysql连接地址，确认网络连通性 2、找运维确认mysql账号情况 3、如果不是连通性或账号问题，那么无法连接上数据库要么连接资源耗尽要么数据库crash了。可参考上面提及到的mysql相关问题|1、监控告警 完善应用对依赖侧的异常监控 2、账号安全 mysql账号由运维和安全团队设置相关权限，研发人员自身需保障账号不外泄， 避免出现外部访问导致运维或安全人员修改账号权限，导致已有应用异常 3、调整优化mysql配置 最大连接数、连接超时时间 4、提升数据库规格 数据库现有规格无法支持现有业务量||
|中间件异常|Redis异常||||||||
|MongoDB异常|1.请求服务超时 写入或者查询的接口时间过长|超时异常导致后续的业务逻辑没有执行|||1.表数据过大（5亿），没有做数据分片且设置合理的索引值||||
|ElasticSearch异常|||||||||
|RocketMQ异常|||||||||
|RabbitMQ异常|1. 性能问题   1） 消息积压：消息的生产速度超过了消费速度，队列中可能会出现消息积压   2） 高publish速率：消息发布（Publish）速率过高，可能超出RabbitMQ集群的处理能力|消息消费慢|查看RabbitMQ的Dashboard来判断Ready消息积压值|自定义消息积压阈值规则|1. 物理节点I/O负载过高 2. 消息发布速率大于处理能力 3. 队列或交换机配置错误 4. 网络问题||||
|Kafka异常|1. 消息堆积 1）消费者出现性能问题导致堵塞：观察生产者的生产速率曲线和消费者生产速率曲线，对消费者出现的的性能问题进行修复。 2) partition设置过少：消费者没有得到充分的分配使用 3) 消费者处理能力不足：消费者提供的线程数量或者同步阻塞的处理时间过长。 4) 生产者生产速率过快，场景没有进行合适的调配。|消费缓慢，异步链路处理阻塞|消息堆积数量惊醒告警|消息堆积数量|1. mysql出现慢sql导致业务系统处理缓慢 2. 系统同步处理消息的线程过少 3. 参与消费的节点过少 4. 消息发布速率大于处理能力 5. 网络问题|1. 观察监控告警：通过promethues将kafka异常指标通知到工作群，在消息堆积的时候第一时间发现 2. 查看kafkaManger（logiKM）：看下消费者和生产者的速率 3. 定位topic和消费组 4. 查看机器的各项指标和数据库mysql的情况 5. 解决系统低性能问题或者扩容|1. 对系统消费者进行压测，确定其能承受的消费速率 2. 配置监控告警实时观测线上情况 3. 规划好应对大促的队列扩容机制||
|Kafka异常|1、多个消费者消息堆积严重 2、kafka消费延迟不断增大 3、使用相同消费者组的其他消费者消费延迟也在不断增大 4、kafka监控可以看到相同消费者组的消费者在不断rebalance|1、消息有消费，但并没有有效提交 2、使用相同消费者组的消费都都会陷入同样的异常情况|多个消费者消息堆积数量惊醒告警|消息堆积数量|1、同一个kafka集群下，多个topic的消费者使用了相同消费组 2、kafka消费者默认一次批量pull的数量是500（max.poll.records） 3、kafka消费者在300s(max.pull.interval.ms)内没有进行再次pull会触发消费组的rebalance 4、多个服务的消费者共用消费者组，由于A服务消费者rebalance导致 B服务的消费者rebalance|1、查看kafka管理控制台，查看消费者是否在不断rebalance 1、查看服务正常启动无异常，是否由于服务异常的原因导致的不断rebalance 2、逐个排查共用消费者组的消费者的处理延迟，计算一个消自息的处理时间。 3、查看是否存在无法在300s内处理完一次批量pull消息的消费者组|1、如果是服务异常不断重启导致的rebalance，则修复服务 2、如果是由于无法在一次pull间隔处理完消息，则配置max.poll.records属性，将其设置为一个较小的值 3、spring cloud stream配置如下 spring:   cloud:     stream:        kafka:          bindings:           orderRefundAutoAuditEventIn:             consumer:               configuration:                 max.poll.records: 10||
|Nacos异常|1.服务启动异常 服务拉取不到nacos配置，导致服务在启动过程中报错； 2.服务感知不到nacos配置变化 在nacos改变配置时，应用不能及时感知到变化； 3.服务调用接口失败 应用通过服务发现调用其他服务接口时，获取不到最新的host列表，导致调用失败；|服务启动失败，服务调用链路中断|jvm metrics Nacos 监控指标 nacos 异常指标 client metrics|[参考： https://nacos.io/zh-cn/docs/v2/guide/admin/monitor-guide.html](https://nacos.io/zh-cn/docs/v2/guide/admin/monitor-guide.html)|1. nacos本身启动失败，通常因为内存不足、端口被占用、配置文件错误等原因造成，可以通过启动日志明确原因； 2. 网络连接异常。通常是防火墙设置等原因造成； 3. 版本兼容性。客户端和nacos服务器版本不一致造成服务连接nacos异常； 4. 权限认证问题。客户端没有提供正确的用户名密码； 5. 健康检查失败。比如服务有太多线程，导致nacos心跳线程经常获取不到cpu资源像nacos服务器发送心跳，这种情况会被nacos服务器任务服务实例下线了； 6. nacos不适合高并发场景，如果有应用把它当做数据库，不停发布拉取新的配置，会导致nacos性能变差，进而导致其他功能异常；|1. 检查nacos服务本身是否异常，可以通过nacos后台管理平台能不能正常登录来判断； 2. 检查网络是否通畅，通过ping telnet等工具检测； 3. 检查用户名密码是否正确； 4. 检查客户端和nacos服务端版本是否一致； 5. 检查服务实例是否经常自动下线； 6. 检查nacos http请求次数指标，如果请求次数过高，说明有应用在不当使用nacos|1. 对nacos运行指标进行监控，可以参考https://nacos.io/zh-cn/docs/v2/guide/admin/monitor-guide.html 2. 给nacos服务器提供足够的资源，如内存，cpu，硬盘。作为一个有状态的中间件，尽量用独享的物理机部署。 3. 避免不当使用nacos，nacos不适合高频率访问||
|Seata异常|||||||||
|网络联通异常|域名DNS解析不通|1、日志出现大量UnknownHost java.net.UnknownHostException cannot resolve xxxxxx: Unknown host 2、服务请求错误率显著上升|1. 部分业务功能故障无法使用 2. 请求阻滞 如未作熔断处理且服务为同步IO，可能导致请求积压阻滞 3. 服务雪崩 关键服务因为网络异常而变慢或宕机，那么所有依赖它的服务都可能受到延迟影响，最终导致整个系统的瘫痪 4. 资源消耗和性能下降 可能导致应用不断尝试重连，从而消耗大量的系统资源（如CPU、内存和网络带宽 5. 数据不一致性 可能导致分布式事务的数据不一致性|日志的IO相关异常的监控告警|日志监控出现异常UnknownHostException|1. 服务的目标域名配置错误 域名在 DNS 服务器上不存在或者被错误配置，例如域名拼写错误、域名未注册等 2. hosts文件配置错误 如果在 hosts 文件中将某个域名解析到了不存在的 IP 地址或者错误的 IP 地址 3. DNS 服务器配置错误 本地 DNS 服务器配置错误，无法正常解析域名 4. 网络故障 如果网络连接出现故障，例如网络断开、DNS 服务器不可达等，就无法进行域名解析 5. DNS缓存旧IP DNS 缓存可能包含过期的或者错误的解析信息，导致解析失败 6. 防火墙屏蔽 如果防火墙配置了特定的规则阻止了 DNS 查询请求，也会导致解析失败|1. 检查应用配置 核对错误日志信息，检查Nacos配置、yaml文件、启动参数、环境变量对应的配置 2. 检查hosts文件（容器与宿主机） 2.1 检查容器和宿主机，cat /etc/hosts查看对应配置 2.2 检查POD的[HostAlias](https://kubernetes.io/docs/tasks/network/customize-hosts-file-for-pods/)配置 3. 检查DNS服务器配置（容器与宿主机） 3.1 nslookup 命令查看DNS解析结果 3.2 cat /etc/resolv.conf 检查DNS服务器IP配置 3.3 cat /etc/nsswitch.conf 检查hosts项:        hosts: files dns(先解析hosts文件后dns服务器) 3.4 检查[CoreDNS](https://coredns.io/plugins/kubernetes/)或KubeDNS配置 kubectl -n kube-system get cm coredns -o yaml 3.4.1 自定义hosts解析特定域名：hosts {...} 3.4.2 特定DNS服务器解析特定域名：domain.53 {... forward . nsserver-ip} 3.4.2 特定DNS服务器解析所有域名(默认8.8.8.8为Google的DNS)：forward . nsserver-ip 4. 访问其他网络 5. 查看DNS缓存 查看nscd 本地缓存 sudo strings /var/cache/nscd/hosts \| uniq sudo nscd -g（查看一般统计信息） 查看dnsmasq 生成的DNS缓存 sudo systemctl status dnsmasq 6. 检查防火墙配置 对于 ubuntu 系统使用 ufw status verbose 查看防火墙策略 对于 iptables 防火墙：可以使用 iptables -L 命令 对于 firewalld 防火墙：可以使用 firewall-cmd --list-all 命令|事前预防： 1. 设置日志监控告警 2. 发布审查 在版本发布文档，增加外部依赖地址检测项，上线前对增加的目标服务器进行可达性检测 3. [工单申请] 申请联通到目标地址的网络路由策略 4. 维护外部依赖信息 维护外部依赖的域名、IP等路由信息，定期检查 5. 维护服务器初始化手册 描述扩充新的服务器后要执行的步骤 手动排障： 1. 修正对应应用配置 2. 修正hosts文件配置 3. 修正对应DNS服务器配置 4. 清理DNS缓存 sudo /etc/init.d/nscd restart sudo nscd -i hosts sudo pkill -USR1 dnsmasq sudo systemd-resolve --flush-caches sudo /etc/init.d/dns-clean start 如果ping正常，但是java应用报错，考虑修改启动参数-Dnetworkaddress.cache.ttl=60 -Dsun.net.inetaddr.ttl=60 5. 清理防火墙策略 使用 -D 参数删除指定的规则。你需要知道要删除的规则的具体匹配条件，例如链的名称和规则的编号： sudo iptables -D INPUT 3 使用 --remove-rule 参数从指定的 zone 或 service 中删除规则。你需要知道要删除的规则的具体内容： sudo firewall-cmd --zone=public --remove-rule=service=dhcp 使用 delete 参数删除指定的规则。你需要知道要删除的规则的具体内容： sudo ufw delete allow 80/tcp|
|路由网络不可达 （ping不通）|1. 日志报错 java.net.NoRouteToHostException、 java.net.ConnectException 2. 业务接口异常5XX报错、网关504超时|日志的IO相关异常的监控告警|1. 日志监控出现异常NoRouteToHostException 2. 日志监控出现异常ConnectException的数量超过阈值|1. java.net.NoRouteToHostException 当没有到目标主机的路由时，会抛出此异常。这可能是由于网络配置错误、网络设备故障或目标网络不可达等原因造成的。 2. java.net.ConnectException 如果域名可以解析，但对应的IP地址不可达（例如，由于网络问题或目标服务器宕机），则可能会抛出此异常|0. 检查应用目标地址配置、提工单开墙 1. 检查网络配置(ifconfig、ip addr) 1.1. 确保本地有效路由的IP地址、子网掩码和网关设置正确 1.2. 确保目标系统的IP地址和子网掩码设置正确 2. 检查路由配置 2.1. 检查路由表配置(route) 2.2. 检查防火墙配置（参考上述描述） 出站规则、入站规则、NAT转换、端口屏蔽、应用层过滤（ 应用层过滤通常是特定防火墙软件提供的高级功能，可以根据不同的防火墙软件使用不同的命令来查看和配置。 对于一些商业防火墙，可能需要通过特定的管理界面或工具来查看和配置应用层过滤规则。） 3. 检查网络连通性 使用 ping 命令测试本地系统与目标主机之间的连通性（注意目标机器防火墙或路由器也可能禁用ICMP响应即ping-pong） 使用 traceroute 或 tracert 命令检查网络路径，确定是否存在网络中断或路由问题。 使用 telnet等其他工具来检测连通性 4. 检查目标主机的可达性 确保目标主机正在运行，并且可以响应网络请求。 检查目标主机的防火墙设置，确保不会阻止连接请求。 5. 检查网络设备状态 提工单联系运维人员检查网络设备（如交换机、路由器）的状态，确保它们正常工作并且没有故障|事前预防： 同上述DNS解析失败解决方案 手动排障： 1. 修正对应应用配置 2. 清理路由配置 route del -net destination_network gw gateway_ip 3. 清理防火墙配置 同上述DNS解析失败解决方案|||
|端口不通 (telnet失败)|1. 日志报错 java.net.ConnectException、 java.net.SocketTimeoutException、 java.net.PortUnreachableException、 java.net.ProtocolException 2. 业务接口异常5XX报错、网关504超时|日志的IO相关异常的监控告警|日志监控出现前述异常数量超过阈值|1. java.net.ConnectException 如果网络可达，防护墙阻止端口连接也有可能出现异常 2. java.net.SocketTimeoutException 当Java应用尝试连接到一个不可达或响应缓慢的服务器时，可能会遇到此异常。这通常发生在设置了连接或读取超时，并且服务器在给定的时间内没有响应的情况下 3. java.net.PortUnreachableException： 端口不可达异常，表示目标主机已经可达，但目标端口未打开或未启动服务。|1. 检查网络可达性 配置、防火墙策略 2. 检查端口访问状态 使用telnet、nc/natcat、curl、wget、nmap等访问远端，ss、netstat、lsof等查看本机监听端口 3. 使用tcpdump抓包|事前预防： 同上述网络不可达解决方案 手动排障： 1. 修正对应应用配置 2. 清理防火墙配置 同上述网络不可达解决方案|||
|基础设施异常|磁盘不足||||||||
|磁盘损坏|||||||||
|磁盘IOWAIT高|||||||||
|服务器CPU高|||||||||
|服务器LOAD高|||||||||
|服务器宕机无响应|||||||||
|K8S集群证书过期|||||||||
|K8S调度资源不足|||||||||
|K8S集群节点故障|||||||||

